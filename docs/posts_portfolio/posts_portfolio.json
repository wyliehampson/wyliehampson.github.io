[
  {
    "path": "posts_portfolio/2024-08-27-dmdu/",
    "title": "Colorado River Basin Post-2026 Operations Exploration Tool",
    "description": "Team: Virga Labs | Client: U.S. Bureau of Reclamation",
    "author": [
      {
        "name": "Wylie Hampson",
        "url": {}
      }
    ],
    "date": "2024-08-27",
    "categories": [],
    "contents": "\n\nOverview\nThis is a walk-through of the work that I did on the Colorado River\nBasin Post-2026 Operations Exploration Tool while working on the Virga\nLabs team from July of 2022 through May of 2024. This tool was built for\nthe U.S. Bureau of Reclamation to allow Colorado River Basin\nstakeholders and the public to explore operational strategies for Lake\nPowell and Lake Mead as part of the Post-2026 National Environmental\nstrategy Act (NEPA) Process. This tool is intended to support\nearly-stage exploration of operational strategies that may eventually be\nincorporated into the Post-2026 NEPA alternatives. A link to the tool\nitself can be found here,\nand it can be explored by anyone that creates an account. This\nwalk-through is more intended to showcase the work that I personally did\nwhile working on this project, and is less intended to showcase the\nwhole tool itself. If you would like to learn more about the whole tool\nand what it is capable of, I recommending going to the website and\nmaking an account and exploring the tool for yourself!\nThe Problem, The\nSolution, and The Data\nThis project uses data produced from a RiverWare model called CRSS\n(Colorado River Simulation System). This model is maintained and updated\nby the U.S. Bureau of Reclamation. This model allows people to feed in\ndifferent inputs (hydrology, demand, initial conditions, and strategy,\nwhich is how the river is managed) and it will return predictive data\nfor the river conditions over the next 60 years. This issue with this\nmodel is that the output data is a large amount of data tables that\naren’t very accessible for the average person. The Bureau of Reclamation\nwanted to make this data more accessible to the average stakeholder so\nthat a large amount of people can all work together to figure out the\nbest ways to manage the water over the next 60 years that make sense to\nas many stakeholders as possible, including the general public. So, this\ntool takes the output data of CRSS and builds many tools and\nvisualizations that allow more people to get more out of it.\nMy Auxilary Contrbutions\nBefore getting into the major sections of this project that I worked\non I wanted to briefly touch on some of the smaller parts of this\nproject that I helped out with. This project was built by a team of\nabout 8 developers (give or take). This meant that I had the opportunity\nto do little bits of work through out this whole application.\nHere are some of the key skills that I was able to pick up\nwhile working on this project (with more description below):\nRShiny front end development\nCSS\nHTML\nJavascript\nNightly and weekly Deployments (manual and setting up CRON\njobs)\nAWS\nAccessing data\nCreating EC2s and AMIs\nWorking with deployment\n\nThis is an RShiny web application (and a very large one at that)\nwhere I learned A LOT about front end RShiny development. Working on\nthis project also gave me a lot of experience in UI/UX, CSS, HTML, and\nJavascript, since much of RShiny is wrapped around those languages, so\nin order to do certain customization, you need to use those languages.\nOnce we began releasing versions of this app to the client and public, I\nwas also responsible for nightly deployments to a dev environment and a\nweekly deployment to a production environment. Lastly, before diving\ndeeper into my main accomplishments in this project, I also was able to\nlearn a fair amount of working with AWS, be it accessing data, creating\nEC2s and AMIs for various environmental metrics that we used in the app,\nor working with deployments.\nMy Main Contributions\nPerformance Tab\nOne area that I spent a lot of energy in was the performance tab of\nthis application. Just to give a very simplified summary of the\nperformance tab, it was used to show users how well their strategy (the\nway they chose to manage the river) performed against different metrics\n(some examples of these metrics are things such as energy production,\nmoney earned from recreation, Lake Mead and Lake Powell water levels,\netc.) I helped with a lot of the UI organization on this tab as well as\nmaking changes to the Parallel Axis Plot when needed. The Performance\nTab consisted of three subtabs, the tradeoff view, the trace view, and\nthe metric explanations.\nTradeoff View\n\nWhen the client requested to add different hydrologies to the\ntradeoff view so that users could see how their strategies performed in\ndifferent potential hydrologic futures, I implemented the drop down that\nallows users to select which hydrology they wanted.\n\nThen, once a user has selected a hydrology, I hooked that up to our\nAPI to retrieve data for that specific hydrology. Once the API returned\nthe correct data, I had it update the Parallel Axis Plot accordingly.\nThis also included changes that needed to be updated in the Trace View\ntab, which I’ll get into next.\nSummary of work done on the Tradeoff View tab:\nBuilt in the functionality for users to select which hydrology to\ncompare\nAdding drop down\nHooking it up to API\nMunge data to update the Parallel Axis Plot\n\nOther UI updates and fixes\nTrace View\n\nThe Trace View section of this application was one of my larger\ncontributions. The Trace View is a more detailed explanation as to how\neach strategy gets its performance score for each metric. Within it,\nusers can select the strategies, metrics, and hydrologies that they are\ninterested in, query the database, and then get some insightful\nvisualizations returned. When I first started working on this project\nthe there was a very initial design for Trace View, but I ended up\nbuilding the majority of it myself, from the UI/UX, to the data\nvisualizations, to connecting everything with the APIs and the data. For\nUI/UX, the drop down menus weren’t too difficult to implement in RShiny,\nbut there were some other more difficult aspects of the Trace View UI. I\nhad to implement a rank list for the selected strategies so that users\ncan choose which order they want them to display in (in screen shot\nabove). This used a package called sortable to create the list itself,\nbut I had to do some hacky javascript to get the background colors of\neach item to match the designated color for that strategy. Once the user\nqueried the database and the visualizations populated, I had to do some\nUI design to get each set of visualizations to show up in collapsible\naccordion boxes. Then within each box there were three different\ncomponents to each strategy/metric combination, which took some work to\nget them to all fit appropriately.\n\nAfter the UI work, there was a lot of behind the scenes work that\nneeded to be done with the data. When a user would select their inputs\nand click the “Calculate Traces” button, something had to happen. In\norder for something to happen I helped hook the button up to the API so\nthat actual data would be retrieved, and then there was a lot of work\nthat I did to get the data to produce the desired plots. Both the\ntimeseries plots and the summary plots were created using the eCharts4r\npackage which required a lot of Javascript to customize the plots to our\nneeds. There is a highlighting functionality that is linked between the\ntimeseries plots and the summary plots that required some difficult\njavascript to produce.\n\nThen for the plots themselves. The data that would get returned from\nthe API would be used to produce the timeseries plots and the summary\nplots. The timeseries plots look at 10 traces for each strategy and each\nmetric. Those traces would then all be averaged to produce the summary\nplot, and then those values would all be averaged to get the final\n“score” for that metric. There is more details of this on the web app\nitself if you are interested in learning more. Each timeseries and\nsummary plot would be different based on what the y-axis units were and\nif the timeseries data was either monthly or annual. This information\nwould all be in the data that gets returned from the API. Once the data\nwas returned from the API it would need to me munged based on different\nfactors in order to fit into the plots that get produced, and I did the\nmajority of that work as well. Lastly, all of the plots had custom hover\nover tool tips that needed to be created using custom javascript which I\nspent a lot of time working on and tweaking over time (seen in above\nimage).\nSummary of work done on the Trace View tab:\nDesigned and implemented UI layout of whole tab\nAdded drop downs to select inputs\nUsed reactives and javascript to get the strategy colors to match in\nthe sortable rank list\nMade the rank list determine the order at which the strategies\nrendered on page\n\nConnected inputs to API to return correct data\nMunged data returned from API to properly produce plots\nDesigned and coded all data visualizations (timeseries plots and\nsummary plots) using eCharts4r and javascript\nUsed reactive values that would change the plot based on units, axis\nlabels, and whether or not it was monthly or annual data\nUsed custom JS to get highlighting functionality to link between\ntimeseries plots and summary plots\nUsed custom JS to customize all of the hover-over tool tips\nUsed reactives to get strategy colors to match individual plots\n\nEnvironemtnal Metrics\nThe next big task that I had on this project was implementing about\n14 environmental metrics that users could compare their strategies with.\nThere were already many other metrics in the tool, but later on in\ndevelopment the client asked that we add some more environmentally\nfocused metrics that some of the users of the tool wanted, many of these\nbeing other governmental and environmental organizations. Some examples\nof the environmental metrics are things such as money earned through\nrecreation in the Grand Canyon, small mouth bass populations, number of\ncertain vegetation populations, etc. The way that the metrics work is\nwhen a user submits a new strategy it gets sent to the back-end and then\nit takes about 4 hours to run through our model and get the output data\nfor each metric. So in order to implement new metrics we needed to run\neach strategy through some code that returns data for that new metric.\nThe nice part is the agencies that wanted the new metrics were able to\nprovide code for us that does all of the complex ecological\ncalculations. So they passed their code to me, and then for each metric\nI had to tweak the code so that it could ingest our data format for all\nof the strategies, and then I would have to make the output data fit our\nback-end model, so that was a decent sized task. This also included\ndoing data validation and making sure that the data that was being\noutput was what we expected and checking with the experts from the other\nagencies to make sure of this. But there was more to it. Once the code\nwas all ready I needed to create an AWS EC2 to boot up and run every\ntime a new strategy was submitted. I had never built an EC2 before so it\ntook some time to learn but I was eventually able to create on that\nbooted up, ran had all of the packages in the environment that it\nneeded. This taught me a lot about EC2s and AMIs and how it all works\nfrom start to finish. Lastly we ran into one other issue during this\ntask. When we ran the vegetation metrics they were extremely slow and\nwould take over 24 hours to run, which meant when a user submitted a new\nstrategy it would take 24 hours instead of 4 because of a few new\nmetrics. The client didn’t want this so we needed to find new ways of\nrunning these. A couple of colleagues and I worked together and\neventually found a new way of running these metrics using parallel\nprocessing and we were eventually able to drop the time down to under\nthat 4 hour mark. Over all adding the environmental metrics to the web\ntool took a lot of work and it was one of my bigger challenges while\nworking on this project, but overall I think I learned more from doing\nit than anything else that I had worked on.\nSummary of work done on the Environmental Metrics:\nTake existing code that wasn’t my own and update it to ingest and\noutput data in our expected formats\nDo data validation with the output data to make sure it is\ncorrect\nSet up an AWS EC2 to have all of the required packages and run the\nnecessary code\nSet the EC2 to run at the proper time in our model runs\nUse parallel processing to reduce code run times from ~24 hours down\nto under 4 hours\nSummary Tab\nComprehensive View\nThe comprehensive view was essentially just a summary of everything\nthat the user explored as they went through the application. I assisted\nin the UI layout and design overtime of this view. The largest\ncontribution that I made on the comprehensive view was the print\nfeature. I added a button that users could press that would open up the\nprint window and have a professional looking print out view of\nComprehensive View tab. This required some CSS and HTML work that made\nsure items weren’t getting cut off and icons were the right size\netc.\n\nSummary of work done on the Comprehensive View tab:\nUI layout changes and design over time\nCreate a print view that allows users to print out a professional\nlooking PDF document with everything that they did in the app\nRisk View\n\nThe Risk View is the other biggest section of the project that I\nworked on (Trace View being the other). Risk View is kind of a\nsimplified version of the overall app. Risk view allows users to select\nthree input: hydrology, initial conditions, and demand. Then they select\nwhich strategies they are interested in and it shows the risk of Lake\nPowell and Lake Mead water levels dropping below specific elevations\nover the next 35 years. There are two sections of Risk View, one where\nthe user selects one strategy and compares it to up to 10 different\nfutures, which are made up of initial condition, hydrology, and demand\ncombinations. And the other is where the user can compare up to 10\ndifferent strategies to one future. I created the Risk View on my own\nfrom the ground up starting with a Figma design concept. I built the two\ndifferent sub tabs and all of the inputs features including the table\nthat adds and removes future selections. Within each subtab there are\nthree plots for selecting each of the three inputs. I built two of the\nthree plots, and I also added the functionality that highlights the\nuser’s selection after they select it from the drop down.\n\nI also used javascript to create the plot legend for the output plots\nas well as reactive UI layouts that render once the user hits the\n“Calculate Risk” button.\n\nI also hooked up the input selections to the API to return the\ncorrect data for the plots, and munged the data itself. The Risk View\nalso gave me the opportunity to assist our backend engineer with\nactually building the API that gets used for the Risk View results\nplots. Then lastly I built the output plots themselves using the\nggplotly package.\n\nSummary of work done on the Risk View tab:\nCreated concept Figma design before building\nBuilt all of the UI\nBuilt input drop downs\nBuilt table that adds and removes future scenarios\nBuilt reactive UI to display plots once they are returned\nUsed custom JS to build plot legend\n\nHooked up inputs with the API to return correct data used for\nplots\nMunged data to work with plots\nBuilt the plots using ggplotly\nConclusion\nAnd that concludes the Colorado River Basin Post-2026 Operations\nExploration Tool. It was definitely the largest project that I have ever\nworked on and I learned an extremely large amount of new skills along\nthe way. It was an honor to be a part of this project and the wonderful\nteam that worked on it and I was very proud to see how the final product\nended up and the impact it can make on protecting the Colorado\nRiver.\n\n\n\n",
    "preview": "posts_portfolio/2024-08-27-dmdu/images/dmdu_art.png",
    "last_modified": "2024-09-05T12:51:52-07:00",
    "input_file": {},
    "preview_width": 452,
    "preview_height": 267
  },
  {
    "path": "posts_portfolio/2024-08-27-riverviz/",
    "title": "RiverViz",
    "description": "Team: Virga Labs | Client: Arizona State University",
    "author": [
      {
        "name": "Wylie Hampson",
        "url": {}
      }
    ],
    "date": "2024-08-27",
    "categories": [],
    "contents": "\n\nOverview\nThis is a walk-through of the work that I did on a project called\nRiverViz while working on the Virga Labs team from July of 2022 through\nMay of 2024. This tool was built for Arizona State University to\ndemocratize access to Colorado River Simulation System (CRSS) model\nresults through approachable formats. The tool provides three different\ndashboards to explore projected reservoir conditions, energy generation\npotential, and water supply availability in the Colorado River Basin. A\nlink to the tool itself can be found here, and it can be explored by\nanyone! This walk-through is more intended to showcase the work that I\npersonally did while working on this project, and is less intended to\nshowcase the whole tool itself. If you would like to learn more about\nthe whole tool and what it is capable of, I recommending going to the\nwebsite and making an account and exploring the tool for yourself!\nMy Main Contributions\nUI Changes\nThroughout this project I helped work on much of the UI of the web\napplication. I helped design the layout of the scenario chooser and I\nhelped with the layouts of the different dashboards. I also helped make\nchanges and adjustments to many of the data visualizations throughout\nthe app as they changed over time.\n\nExplanatory Content\nEach data visualization in this plot comes with a drop down section\nunderneath it that explains what the graph is showing. A colleague and I\nspent time going through each visual and making sure that the\nexplanations were both accurate and helpful.\n\nData Validation\nThe largest task that I worked on for this project was data\nvalidation. When I was first brought onto this project many of the\nvisualizations were already developed. But, my first task was to go\nthrough each visual and check the SQL query that was being used to get\nthe data for that visual. This involved navigating code written by\nothers and finding in-house functions that enabled the display of the\nSQL queries. Once I was able to see each query for each visual I then\nhad to go through and make sure the SQL code was correct and that it was\nin fact returning the data that we wanted in order to display what we\nwere saying the plots were displaying. CRSS has many different tables\nthat it contains so I also had to do a lot of checking with my manager\nand other colleague to check the raw data itself. Any errors that I did\nfind I would then need to check with our backend engineer and assist in\ncorrecting the queries to return what we actually wanted. This was a\ndifficult task but ultimately I enjoyed because it helped me learn a lot\nabout SQL and the importance of data validation. It’s too easy to create\na data visualization that isn’t actually accurate, so it’s so important\nto make sure that everything is correct before releasing it to the\npublic.\n\n\n\n",
    "preview": "posts_portfolio/2024-08-27-riverviz/images/riverviz_art.png",
    "last_modified": "2024-09-05T12:55:04-07:00",
    "input_file": {},
    "preview_width": 450,
    "preview_height": 266
  }
]
